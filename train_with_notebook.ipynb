{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training records\n",
    "* This code same with 'train.py'\n",
    "* Check the hyper parameters in 'hyperparams.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 10, 2)        184320      primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_1 (Mask)                   (None, 20)           0           digitcaps[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (CapsLength)            (None, 10)           0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 28, 28, 1)    1339664     mask_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,853,648\n",
      "Trainable params: 6,853,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.7513 - capsnet_loss: 0.7228 - decoder_loss: 0.0727 - capsnet_acc: 0.1793 - val_loss: 0.0955 - val_capsnet_loss: 0.0748 - val_decoder_loss: 0.0528 - val_capsnet_acc: 0.9486\n",
      "\n",
      "Epoch 00001: val_capsnet_acc improved from -inf to 0.94860, saving model to models/model-2d.h5\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0492 - capsnet_loss: 0.0300 - decoder_loss: 0.0491 - capsnet_acc: 0.9776 - val_loss: 0.0346 - val_capsnet_loss: 0.0168 - val_decoder_loss: 0.0454 - val_capsnet_acc: 0.9873\n",
      "\n",
      "Epoch 00002: val_capsnet_acc improved from 0.94860 to 0.98730, saving model to models/model-2d.h5\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0315 - capsnet_loss: 0.0144 - decoder_loss: 0.0435 - capsnet_acc: 0.9893 - val_loss: 0.0284 - val_capsnet_loss: 0.0120 - val_decoder_loss: 0.0421 - val_capsnet_acc: 0.9908\n",
      "\n",
      "Epoch 00003: val_capsnet_acc improved from 0.98730 to 0.99080, saving model to models/model-2d.h5\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0265 - capsnet_loss: 0.0102 - decoder_loss: 0.0417 - capsnet_acc: 0.9926 - val_loss: 0.0269 - val_capsnet_loss: 0.0107 - val_decoder_loss: 0.0414 - val_capsnet_acc: 0.9912\n",
      "\n",
      "Epoch 00004: val_capsnet_acc improved from 0.99080 to 0.99120, saving model to models/model-2d.h5\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0236 - capsnet_loss: 0.0076 - decoder_loss: 0.0408 - capsnet_acc: 0.9949 - val_loss: 0.0246 - val_capsnet_loss: 0.0087 - val_decoder_loss: 0.0404 - val_capsnet_acc: 0.9927\n",
      "\n",
      "Epoch 00005: val_capsnet_acc improved from 0.99120 to 0.99270, saving model to models/model-2d.h5\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0216 - capsnet_loss: 0.0058 - decoder_loss: 0.0402 - capsnet_acc: 0.9965 - val_loss: 0.0238 - val_capsnet_loss: 0.0081 - val_decoder_loss: 0.0400 - val_capsnet_acc: 0.9931\n",
      "\n",
      "Epoch 00006: val_capsnet_acc improved from 0.99270 to 0.99310, saving model to models/model-2d.h5\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0199 - capsnet_loss: 0.0043 - decoder_loss: 0.0397 - capsnet_acc: 0.9974 - val_loss: 0.0235 - val_capsnet_loss: 0.0081 - val_decoder_loss: 0.0393 - val_capsnet_acc: 0.9934\n",
      "\n",
      "Epoch 00007: val_capsnet_acc improved from 0.99310 to 0.99340, saving model to models/model-2d.h5\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0188 - capsnet_loss: 0.0034 - decoder_loss: 0.0393 - capsnet_acc: 0.9982 - val_loss: 0.0223 - val_capsnet_loss: 0.0069 - val_decoder_loss: 0.0393 - val_capsnet_acc: 0.9939\n",
      "\n",
      "Epoch 00008: val_capsnet_acc improved from 0.99340 to 0.99390, saving model to models/model-2d.h5\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0178 - capsnet_loss: 0.0025 - decoder_loss: 0.0390 - capsnet_acc: 0.9990 - val_loss: 0.0223 - val_capsnet_loss: 0.0071 - val_decoder_loss: 0.0388 - val_capsnet_acc: 0.9926\n",
      "\n",
      "Epoch 00009: val_capsnet_acc did not improve from 0.99390\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0170 - capsnet_loss: 0.0019 - decoder_loss: 0.0386 - capsnet_acc: 0.9993 - val_loss: 0.0226 - val_capsnet_loss: 0.0075 - val_decoder_loss: 0.0386 - val_capsnet_acc: 0.9937\n",
      "\n",
      "Epoch 00010: val_capsnet_acc did not improve from 0.99390\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0164 - capsnet_loss: 0.0015 - decoder_loss: 0.0381 - capsnet_acc: 0.9995 - val_loss: 0.0226 - val_capsnet_loss: 0.0076 - val_decoder_loss: 0.0383 - val_capsnet_acc: 0.9937\n",
      "\n",
      "Epoch 00011: val_capsnet_acc did not improve from 0.99390\n"
     ]
    }
   ],
   "source": [
    "from models import base_model\n",
    "from utils import *\n",
    "from hyperparams import * # Check the hyper parameters in 'hyperparams.py'\n",
    "from keras import callbacks, optimizers\n",
    "from keras import backend as K\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    # original source code from \n",
    "    # https://github.com/XifengGuo/CapsNet-Keras\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "    return K.mean(K.sum(L, 1))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = load_mnist()\n",
    "    x_shape = x_train[0].shape\n",
    "    y_shape = y_train[0].shape\n",
    "    \n",
    "    # Init the baseline model\n",
    "    train_model, _ , _ , _ = base_model(input_shape = x_shape, output_shape = y_shape)\n",
    "    \n",
    "    # Init callback functions\n",
    "    checkpoint = callbacks.ModelCheckpoint(MODEL_PATH, \n",
    "                                           monitor='val_capsnet_acc', \n",
    "                                           save_best_only=True, \n",
    "                                           save_weights_only=True, \n",
    "                                           verbose=1)\n",
    "    earlystopper = callbacks.EarlyStopping(monitor='val_capsnet_acc', \n",
    "                                           patience=3, \n",
    "                                           verbose=0)\n",
    "    \n",
    "    # Compile the training model\n",
    "    train_model.compile(optimizer=optimizers.Adam(lr=LearningRate), \n",
    "                        loss=[margin_loss, 'mse'], # classification error & reconstruction error\n",
    "                        loss_weights=[1., LAM_RECON], \n",
    "                        metrics={'capsnet': 'accuracy'})\n",
    "    \n",
    "    # Train model\n",
    "    train_model.fit([x_train, y_train], \n",
    "                    [y_train, x_train], \n",
    "                    batch_size = BATCH_SIZE, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=[[x_test, y_test], [y_test, x_test]], \n",
    "                    callbacks=[earlystopper, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
